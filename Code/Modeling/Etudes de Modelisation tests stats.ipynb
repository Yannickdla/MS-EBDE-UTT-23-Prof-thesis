{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv, to_datetime, DataFrame, concat\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import sqrt, exp, log,zeros, nan\n",
    "from scipy.stats import probplot\n",
    "from pingouin import multivariate_normality \n",
    "\n",
    "from statsmodels.tsa.vector_ar.var_model import VAR,VARResults\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.stats.stattools import jarque_bera\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score,root_mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les fonctions qui seront utilisées "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_ajuste(r2,n,p):\n",
    "\n",
    "    return  1 - (  ((1 - r2) * (n - 1)) / (n - p - 1)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_transformation(df_original, df_forecast, transfo):\n",
    "    \"\"\"\n",
    "    \n",
    "    Revert back the differencing to get the forecast to original scale.\n",
    "    \n",
    "    \"\"\"\n",
    "    df_train = df_original.copy()\n",
    "    df_fc = df_forecast.copy()\n",
    "    df_fcout = df_forecast.copy()\n",
    "    columns = df_forecast.columns\n",
    "    \n",
    "    for col in columns:\n",
    "        # Retirer le logarithme si nécessaire\n",
    "        if transfo.loc[ 'loga'] == 1:\n",
    "            df_fcout[col] = exp(df_fcout[col])\n",
    "        \n",
    "        # Récupérer l'ordre de différenciation\n",
    "        diff_order = transfo.loc[ 'ordreP']\n",
    "        \n",
    "        # Inverser la différenciation uniquement si l'ordre est 3\n",
    "        if diff_order > 0 :\n",
    "            for i in range(diff_order):\n",
    "                df_fcout[col].iloc[i] = df_train[col].iloc[i]\n",
    "            for j in range(diff_order, len(df_train[col])):\n",
    "                df_fcout.loc[j,col] = df_fcout.loc[j - diff_order,col] + df_fc.loc[j,col]\n",
    "            \n",
    "        elif diff_order == 0:\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"Vous n'avez pas fourni un bon ordre de différentiation. il est de {diff_order}\")\n",
    "\n",
    "    return df_fcout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import des dataframes d'informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOrig = read_csv(\"Product families over time.csv\")\n",
    "dfOrig = dfOrig.set_index('Product Family').T\n",
    "dfOrig.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "df2 = dfOrig.copy()\n",
    "\n",
    "# Liste des familles de séries temporelles\n",
    "\n",
    "def determine_petit_truc(series):\n",
    "    min_positive_value = series[series > 0].min()\n",
    "    val = 0.00001\n",
    "    return min_positive_value * val\n",
    "\n",
    "# Fonction pour tester la stationnarité avec le test ADF\n",
    "def test_stationarity(series):\n",
    "    result = adfuller(series.dropna())\n",
    "    return result[1]  # Retourne la p-value\n",
    "\n",
    "# Fonction pour appliquer la transformation logarithmique\n",
    "def apply_log(series, p):\n",
    "    return log(series + p)\n",
    "\n",
    "# Initialiser un DataFrame pour enregistrer les résultats\n",
    "results_df = DataFrame(columns=[\"family\", \"ordreP\", \"loga\"])\n",
    "fams = df2.columns\n",
    "\n",
    "results_list = []\n",
    "stat_data = dict()\n",
    "# Traiter chaque famille de séries temporelles\n",
    "for family in fams:\n",
    "    #print(f\"\\nTraitement de la famille: {family}\")  \n",
    "    series = df2[family].dropna()\n",
    "    p_val = test_stationarity(series)\n",
    "    ordreP = 0\n",
    "    loga = 0\n",
    "    petit_truc = determine_petit_truc(df2[family])\n",
    "    if p_val < 0.05:\n",
    "        stat_data[family] = series\n",
    "    # Tester la stationnarité de la série originale  \n",
    "    if p_val > 0.05:\n",
    "        # Appliquer des différentiations successives\n",
    "        for p in range(1, 6):\n",
    "            diff_series = series.diff(periods=p).dropna()\n",
    "            p_val = test_stationarity(diff_series)\n",
    "            if p_val <= 0.05:\n",
    "                ordreP = p\n",
    "                stat_data[family] = diff_series\n",
    "                break    \n",
    "        # Si toujours non stationnaire après différentiation\n",
    "        if p_val > 0.05:\n",
    "            # Appliquer une transformation logarithmique\n",
    "            log_series = apply_log(series, p=petit_truc)\n",
    "            loga = 1        \n",
    "            # Tester la stationnarité de la série log-transformée\n",
    "            p_val = test_stationarity(log_series)\n",
    "            if p_val > 0.05:\n",
    "                # Appliquer des différentiations successives sur la série log-transformée\n",
    "                for p in range(1, 6):\n",
    "                    diff_log_series = log_series.diff(periods=p).dropna()\n",
    "                    p_val = test_stationarity(diff_log_series)\n",
    "                    if p_val <= 0.05:\n",
    "                        ordreP = p\n",
    "                        stat_data[family] = diff_log_series\n",
    "                        break\n",
    "\n",
    "stat_data = DataFrame(stat_data)\n",
    "#print(\"\\nRésultats finaux:\")\n",
    "\n",
    "df_diff = stat_data.copy()\n",
    "#stat_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clust = read_csv(\"pf+clusters+dtw+complete.csv\")\n",
    "df_clust = df_clust.rename(columns={\"clusters.norm\": \"clusters\"}) \n",
    "df_clust = df_clust.drop(columns= \"Unnamed: 0\")\n",
    "\n",
    "df_list_diffs = read_csv(\"stationnarity_steps.csv\")\n",
    "\n",
    "dictTransformations = df_list_diffs.set_index('family')\n",
    "\n",
    "#df_clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlags_per_cluster = {\n",
    "    1: 2,  # Cluster 1 avec maxlags = 4\n",
    "    2: 4,  # Cluster 2 avec maxlags = 3\n",
    "    3: 4,  # Cluster 3 avec maxlags = 2\n",
    "}\n",
    "\n",
    "for cluster in df_clust['clusters'].unique():\n",
    "    # Sélectionner les familles de produits appartenant à ce cluster\n",
    "    families_in_cluster = df_clust[df_clust['clusters'] == cluster]['productfamilies']\n",
    "    print(\"Cluster Numéro {0}\".format(cluster))\n",
    "    # Sélectionner les colonnes correspondantes dans le DataFrame des séries différentiées\n",
    "    cluster_data = df_diff[families_in_cluster].dropna()\n",
    "    mlg = maxlags_per_cluster[cluster]\n",
    "    # Exécuter le test de causalité de Granger pour le cluster\n",
    "    granger_results = granger_causality_test(data = cluster_data, maxlag=mlg)\n",
    "    \n",
    "    # Afficher les résultats\n",
    "    for (predictor, target), result in granger_results.items():\n",
    "        p_values = [round(test[0]['ssr_ftest'][1], 4) for test in result.values()]\n",
    "        print(f'Granger Causality test: {predictor} causes {target} with p-values {p_values}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## division pour avoir le jeu d'entrainement et le jeu de test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 45\n",
      "Test set: 8\n"
     ]
    }
   ],
   "source": [
    "# Définir le point de division\n",
    "split_point = int(len(df_diff) * 0.85)  # 85% des données pour l'entraînement\n",
    "\n",
    "# Diviser les données\n",
    "df_train = df_diff.iloc[:split_point]\n",
    "df_test = df_diff.iloc[split_point:]\n",
    "\n",
    "# Vérifier les tailles des ensembles d'entraînement et de test\n",
    "print('Training set:', len(df_train))\n",
    "print('Test set:', len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choix du maxlag un peu au piff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choix du p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlags_per_cluster = {\n",
    "    1: 2,  # Cluster 1 avec maxlags = 4\n",
    "    2: 4,  # Cluster 2 avec maxlags = 3\n",
    "    3: 4,  # Cluster 3 avec maxlags = 2\n",
    "}\n",
    "orderVar = dict()\n",
    "orderP = dict()\n",
    "for cluster in df_clust['clusters'].unique():\n",
    "    # Sélectionner les familles de produits appartenant à ce cluster\n",
    "    families_in_cluster = df_clust[df_clust['clusters'] == cluster]['productfamilies']\n",
    "    print(\"Cluster Numéro {0}\".format(cluster))\n",
    "    # Sélectionner les colonnes correspondantes dans le DataFrame des séries différentiées\n",
    "    cluster_data = df_train[families_in_cluster].dropna()\n",
    "    \n",
    "    # Ajuster le modèle VAR\n",
    "    model = VAR(cluster_data)\n",
    "    mlg = maxlags_per_cluster[cluster]\n",
    "    # Choisir l'ordre optimal p pour le modèle VAR\n",
    "    order_selection = model.select_order(maxlags=mlg)\n",
    "    best_p = order_selection.aic  # Utilisez aic, bic, fpe ou hqic en fonction de votre préférence\n",
    "    \n",
    "    # Ajuster le modèle VAR avec le meilleur ordre p\n",
    "    results = model.fit(best_p)\n",
    "    print('order of var for the cluster {0} is {1}'.format(cluster,results.k_ar))\n",
    "    orderVar[cluster] = results.k_ar\n",
    "    orderP[cluster] = best_p\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests statistiques "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dictionnaire des ordre du modèle VAR par cluster\n",
    "#### orderVar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affichage des résidus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordervarclust = { 2: 2,  3: 1, 1:1}\n",
    "for cluster in df_clust['clusters'].unique():\n",
    "\n",
    "    families_in_cluster = df_clust[df_clust['clusters'] == cluster]['productfamilies']\n",
    "    # Sélectionner les colonnes correspondantes dans le DataFrame des séries différentiées\n",
    "    cluster_data = df_train[families_in_cluster].dropna()\n",
    "   \n",
    "    print(\"Cluster Numéro {0}\".format(cluster))\n",
    "    model = VAR(cluster_data)\n",
    "    order = ordervarclust[cluster]\n",
    "    results = model.fit(order)\n",
    "    residuals = results.resid\n",
    "    for col in residuals.columns:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "        plot_acf(residuals[col], ax=axes[0])\n",
    "        axes[0].set_title(f'Autocorrélation des résidus pour {col} du cluster {cluster}')\n",
    "    \n",
    "        plot_pacf(residuals[col], ax=axes[1])\n",
    "        axes[1].set_title(f'Autocorrélation partielle des résidus pour {col} du cluster {cluster}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## les résidus du cluster 1 et 2 semblent être des bruits blancs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test de jarque_bera : test de normalité des erreurs \n",
    "\n",
    "## lhypothèse H0 est stipule que les données suivent une loi normale \n",
    "## si la p-value est < à 0.05, on rejète l'hypothèse nulle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordervarclust = { 2: 2,  3: 1, 1:1}\n",
    "for cluster in df_clust['clusters'].unique():\n",
    "\n",
    "    families_in_cluster = df_clust[df_clust['clusters'] == cluster]['productfamilies']\n",
    "    # Sélectionner les colonnes correspondantes dans le DataFrame des séries différentiées\n",
    "    cluster_data = df_train[families_in_cluster].dropna()\n",
    "   \n",
    "    print(\"Cluster Numéro {0}\".format(cluster))\n",
    "    model = VAR(cluster_data)\n",
    "    order = ordervarclust[cluster]\n",
    "    results = model.fit(order)\n",
    "    residuals = results.resid\n",
    "    for col in residuals.columns:\n",
    "        print(f\"Résidus pour {col}:\")\n",
    "        jb_test = jarque_bera(residuals[col])\n",
    "        print(f\"Test de Jarque-Bera: statistic={jb_test[0]}, p-value={jb_test[1]}\")\n",
    "        if jb_test[1] < 0.05:\n",
    "            fig, ax = plt.subplots(figsize=(15, 5))\n",
    "            # QQ-plot\n",
    "            probplot(residuals[col], dist=\"norm\", plot=ax)\n",
    "            ax.set_title(f'QQ-plot {col} in cluster {cluster}')\n",
    "            plt.show()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test de normalité multivaiée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Numéro 2\n",
      "HZResults(hz=0.9175576850625219, pval=0.11061067643715977, normal=True)\n",
      "Cluster Numéro 3\n",
      "HZResults(hz=0.7411591478580923, pval=0.22929233715876157, normal=True)\n",
      "Cluster Numéro 1\n",
      "HZResults(hz=168, pval=0.0, normal=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\WK\\ydongue\\AppData\\Local\\anaconda3\\envs\\devdaveyBickford\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "d:\\WK\\ydongue\\AppData\\Local\\anaconda3\\envs\\devdaveyBickford\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "d:\\WK\\ydongue\\AppData\\Local\\anaconda3\\envs\\devdaveyBickford\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    }
   ],
   "source": [
    "ordervarclust = { 2: 2,  3: 1, 1:1}\n",
    "for cluster in df_clust['clusters'].unique():\n",
    "\n",
    "    families_in_cluster = df_clust[df_clust['clusters'] == cluster]['productfamilies']\n",
    "    # Sélectionner les colonnes correspondantes dans le DataFrame des séries différentiées\n",
    "    cluster_data = df_train[families_in_cluster].dropna()\n",
    "   \n",
    "    print(\"Cluster Numéro {0}\".format(cluster))\n",
    "    model = VAR(cluster_data)\n",
    "    order = ordervarclust[cluster]\n",
    "    results = model.fit(order)\n",
    "    residuals = results.resid\n",
    "\n",
    "    data = residuals\n",
    "    print(multivariate_normality(data, alpha=.05) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QQplot pour la normalité des résidus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordervarclust = { 2: 2,  3: 1, 1:1}\n",
    "qqFamily = \"F_DTC\"\n",
    "for cluster in df_clust['clusters'].unique():\n",
    "\n",
    "    families_in_cluster = df_clust[df_clust['clusters'] == cluster]['productfamilies']\n",
    "    # Sélectionner les colonnes correspondantes dans le DataFrame des séries différentiées\n",
    "    cluster_data = df_train[families_in_cluster].dropna()\n",
    "   \n",
    "    print(\"Cluster Numéro {0}\".format(cluster))\n",
    "    model = VAR(cluster_data)\n",
    "    order = ordervarclust[cluster]\n",
    "    results = model.fit(order)\n",
    "    residuals = results.resid\n",
    "    for col in residuals.columns:\n",
    "        if col == qqFamily:\n",
    "            fig, ax = plt.subplots(figsize=(15, 5))\n",
    "            # QQ-plot\n",
    "            probplot(residuals[col], dist=\"norm\", plot=ax)\n",
    "            ax.set_title(f'QQ-plot {col}')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## le test ne semble pas passer pour la famille B du cluster 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test de acorr_ljungbox : autocorrelation des erreurs \n",
    "\n",
    "## lhypothèse H0 stipule qu'il n'y a pas d'autocorrlation entre les erreurs d'ordre 1 à p\n",
    "## si la p-value est < à 0.05, on rejète l'hypothèse nulle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Numéro 2\n",
      "      Variable  Lag  LB Statistic  LB P-value\n",
      "0        F_CRD    1      0.007047    0.933097\n",
      "1        F_CRD    2      0.267037    0.875011\n",
      "2        F_CRD    3      1.083437    0.781074\n",
      "3        F_CRD    4      1.675076    0.795240\n",
      "4        F_DEL    1      0.001390    0.970261\n",
      "5        F_DEL    2      0.432202    0.805654\n",
      "6        F_DEL    3      0.524954    0.913376\n",
      "7        F_DEL    4      1.575323    0.813220\n",
      "8   F_DIV_MCTP    1      0.339158    0.560316\n",
      "9   F_DIV_MCTP    2      1.947289    0.377704\n",
      "10  F_DIV_MCTP    3      2.418300    0.490237\n",
      "11  F_DIV_MCTP    4      2.780548    0.595195\n",
      "12       F_DPY    1      0.208223    0.648164\n",
      "13       F_DPY    2      0.886944    0.641804\n",
      "14       F_DPY    3      0.931914    0.817720\n",
      "15       F_DPY    4      1.025156    0.905958\n",
      "16       F_FIL    1      0.002970    0.956540\n",
      "17       F_FIL    2      0.435820    0.804198\n",
      "18       F_FIL    3      0.806713    0.847861\n",
      "19       F_FIL    4      1.002452    0.909424\n",
      "Cluster Numéro 3\n",
      "   Variable  Lag  LB Statistic  LB P-value\n",
      "0     F_DEF    1      1.621592    0.202870\n",
      "1     F_DEF    2      2.807036    0.245731\n",
      "2     F_DEF    3      2.855656    0.414420\n",
      "3     F_DEF    4      3.535675    0.472475\n",
      "4     F_DNE    1      0.028056    0.866977\n",
      "5     F_DNE    2      0.640981    0.725793\n",
      "6     F_DNE    3      1.196005    0.753963\n",
      "7     F_DNE    4      1.405908    0.843168\n",
      "8     F_DTC    1      0.049018    0.824780\n",
      "9     F_DTC    2      0.663973    0.717497\n",
      "10    F_DTC    3      0.717643    0.869046\n",
      "11    F_DTC    4      0.949203    0.917398\n",
      "Cluster Numéro 1\n",
      "     Variable  Lag  LB Statistic  LB P-value\n",
      "0       F_DT5    1           NaN         NaN\n",
      "1       F_DT5    2           NaN         NaN\n",
      "2   F_DTC_BTY    1      0.130880    0.717522\n",
      "3   F_DTC_BTY    2      3.205083    0.201384\n",
      "4       F_EBC    1      0.018597    0.891528\n",
      "5       F_EBC    2      7.903976    0.019216\n",
      "6      F_EDGE    1      0.088877    0.765610\n",
      "7      F_EDGE    2      2.873742    0.237670\n",
      "8       F_MUD    1      1.836374    0.175377\n",
      "9       F_MUD    2     10.346921    0.005665\n",
      "10      F_OUD    1      1.742679    0.186800\n",
      "11      F_OUD    2      3.567445    0.168012\n",
      "12      F_SEC    1      0.002328    0.961513\n",
      "13      F_SEC    2      0.219915    0.895872\n",
      "14      F_SPE    1      0.422599    0.515643\n",
      "15      F_SPE    2      0.854396    0.652334\n",
      "16       F_WP    1           NaN         NaN\n",
      "17       F_WP    2           NaN         NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\WK\\ydongue\\AppData\\Local\\anaconda3\\envs\\devdaveyBickford\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "d:\\WK\\ydongue\\AppData\\Local\\anaconda3\\envs\\devdaveyBickford\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "d:\\WK\\ydongue\\AppData\\Local\\anaconda3\\envs\\devdaveyBickford\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "d:\\WK\\ydongue\\AppData\\Local\\anaconda3\\envs\\devdaveyBickford\\Lib\\site-packages\\statsmodels\\tsa\\stattools.py:693: RuntimeWarning: invalid value encountered in divide\n",
      "  acf = avf[: nlags + 1] / avf[0]\n"
     ]
    }
   ],
   "source": [
    "ordervarclust = { 2: 2,  3: 1, 1:1}\n",
    "maxlags_per_cluster = {\n",
    "    1: 2,  # Cluster 1 avec maxlags = 4\n",
    "    2: 4,  # Cluster 2 avec maxlags = 3\n",
    "    3: 4,  # Cluster 3 avec maxlags = 2\n",
    "}\n",
    "for cluster in df_clust['clusters'].unique():\n",
    "\n",
    "    families_in_cluster = df_clust[df_clust['clusters'] == cluster]['productfamilies']\n",
    "    # Sélectionner les colonnes correspondantes dans le DataFrame des séries différentiées\n",
    "    cluster_data = df_train[families_in_cluster].dropna()\n",
    "    mlg = maxlags_per_cluster[cluster]\n",
    "    print(\"Cluster Numéro {0}\".format(cluster))\n",
    "    model = VAR(cluster_data)\n",
    "    order = ordervarclust[cluster]\n",
    "    results = model.fit(order)\n",
    "    residuals = results.resid\n",
    "    results_list = list()\n",
    "    #results_df = DataFrame(columns=['Variable', 'Lag', 'LB Statistic', 'LB P-value'])\n",
    "\n",
    "    # Effectuer le test de Ljung-Box pour des décalages de 1 à maxlag\n",
    "    for col in residuals.columns:\n",
    "        for lag in range(1, mlg+1):\n",
    "            lb_test = acorr_ljungbox(residuals[col], lags=[lag], return_df=True)\n",
    "            results_list.append({\n",
    "                'Variable': col,\n",
    "                'Lag': lag,\n",
    "                'LB Statistic': lb_test['lb_stat'].values[0],\n",
    "                'LB P-value': lb_test['lb_pvalue'].values[0]\n",
    "            })\n",
    "    results_df = DataFrame(results_list)\n",
    "    print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## auto correlation au niveau des lags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordervarclust = { 2: 2,  3: 1, 1:1}\n",
    "maxlags_per_cluster = {\n",
    "    1: 2,  # Cluster 1 avec maxlags = 4\n",
    "    2: 4,  # Cluster 2 avec maxlags = 3\n",
    "    3: 4,  # Cluster 3 avec maxlags = 2\n",
    "}\n",
    "for cluster in df_clust['clusters'].unique():\n",
    "\n",
    "    families_in_cluster = df_clust[df_clust['clusters'] == cluster]['productfamilies']\n",
    "    # Sélectionner les colonnes correspondantes dans le DataFrame des séries différentiées\n",
    "    cluster_data = df_train[families_in_cluster].dropna()\n",
    "    mlg = maxlags_per_cluster[cluster]\n",
    "    print(\"Cluster Numéro {0}\".format(cluster))\n",
    "    model = VAR(cluster_data)\n",
    "    order = ordervarclust[cluster]\n",
    "    results = model.fit(order)\n",
    "    results.plot_acorr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27472112789737807\n"
     ]
    }
   ],
   "source": [
    "# 2sqrt(T)\n",
    "print(2/sqrt(53))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary du modèle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordervarclust = { 2: 2,  3: 1, 1:1}\n",
    "maxlags_per_cluster = {\n",
    "    1: 2,  # Cluster 1 avec maxlags = 4\n",
    "    2: 4,  # Cluster 2 avec maxlags = 3\n",
    "    3: 4,  # Cluster 3 avec maxlags = 2\n",
    "}\n",
    "for cluster in df_clust['clusters'].unique():\n",
    "\n",
    "    families_in_cluster = df_clust[df_clust['clusters'] == cluster]['productfamilies']\n",
    "    # Sélectionner les colonnes correspondantes dans le DataFrame des séries différentiées\n",
    "    cluster_data = df_train[families_in_cluster].dropna()\n",
    "    mlg = maxlags_per_cluster[cluster]\n",
    "    print(\"Cluster Numéro {0}\".format(cluster))\n",
    "    model = VAR(cluster_data)\n",
    "    order = ordervarclust[cluster]\n",
    "    results = model.fit(order)\n",
    "    print(results.summary())\n",
    "\n",
    "## grande correlation entre E et F dans le cluster 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devdaveyBickford",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
