{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## le but de ce notebook est de réussir à construire un modèle VAR  pour fit sur nos données de vente\n",
    "## On va implémenter ici les bonnes métriques pour les modèles "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les fonctions qui vont être utilisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_ajuste(r2,n,p):\n",
    "\n",
    "    return  1 - (  ((1 - r2) * (n - 1)) / (n - p - 1)  )\n",
    "\n",
    "def determine_petit_truc(series):\n",
    "    min_positive_value = series[series > 0].min()\n",
    "    val = 0.00001\n",
    "    return min_positive_value * val\n",
    "\n",
    "# Fonction pour tester la stationnarité avec le test ADF\n",
    "def test_stationarity(series):\n",
    "    result = adfuller(series.dropna())\n",
    "    return result[1]  # Retourne la p-value\n",
    "\n",
    "# Fonction pour appliquer la transformation logarithmique\n",
    "def apply_log(series, p):\n",
    "    return np.log(series + p)\n",
    "\n",
    "## reconstruction pour un dataframe \n",
    "def deDiff(orig, diff,order,log_order):\n",
    "    dfout = pd.DataFrame(index=orig.index, columns=orig.columns)\n",
    "    cols = orig.columns\n",
    "\n",
    "    for family in cols:\n",
    "        #affectation des premières valeurs \n",
    "        dfout[family].iloc[:order] = orig[family].iloc[:order]\n",
    "        # recontruction du reste\n",
    "        for i in range(order, len(orig)):\n",
    "            dfout[family].iloc[i] = dfout[family].iloc[i-order]  +  diff[family].iloc[i-order]\n",
    "        dfout[family]\n",
    "        if log_order == 1:\n",
    "            dfout = np.exp(dfout)\n",
    "    return dfout\n",
    "\n",
    "## reconstruction pour une colonne de dataframe \n",
    "\n",
    "def deDiffFamily(orig, diff, order,log_order):\n",
    "    \n",
    "    \"\"\"\n",
    "    Fonction poure reconstruire les colonnes de dataframes à différenciation\n",
    "    orig = la colonne originale\n",
    "    diff = la colonne des valuers différenciées\n",
    "    order = l'ordre de différentiation de la colone\n",
    "    log_order = 1 si on a utilisé un logarithme et 0 sinon\n",
    "    \"\"\"\n",
    "    \n",
    "    dfout = pd.Series(index=orig.index, dtype=orig.dtype)\n",
    "    dfout.iloc[:order] = orig.iloc[:order]\n",
    "    for i in range(order, len(orig)):\n",
    "        dfout.iloc[i] = dfout.iloc[i-order] + diff.iloc[i-order]\n",
    "    if log_order == 1:\n",
    "        dfout = np.exp(dfout)\n",
    "    return dfout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement du Jeu de données de ventes, des informations de cluster et des étapes de différenciation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOrig = pd.read_csv(\"Product families over time.csv\")\n",
    "dfOrig = dfOrig.set_index('Product Family').T\n",
    "\n",
    "df_clust = pd.read_csv(\"pf+clusters+dtw+complete.csv\")\n",
    "df_clust = df_clust.rename(columns={\"clusters.norm\": \"clusters\"}) \n",
    "df_clust = df_clust.drop(columns= \"Unnamed: 0\")\n",
    "\n",
    "df_list_diffs = pd.read_csv(\"stationnarity_steps.csv\")\n",
    "dictTransformations = df_list_diffs.set_index('family')\n",
    "#dictTransformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul des différentes transformations (diff et log ) pour rendre les données stationnaires "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = dfOrig.copy()\n",
    "\n",
    "# Initialiser un DataFrame pour enregistrer les résultats\n",
    "results_df = pd.DataFrame(columns=[\"family\", \"ordreP\", \"loga\"])\n",
    "results_list = list()\n",
    "fams = df2.columns\n",
    "\n",
    "stat_data = dict()\n",
    "# Traiter chaque famille de séries temporelles\n",
    "for family in fams:\n",
    "    #print(f\"\\nTraitement de la famille: {family}\")  \n",
    "    series = df2[family].dropna()\n",
    "    p_val = test_stationarity(series)\n",
    "    ordreP = 0\n",
    "    loga = 0\n",
    "    petit_truc = determine_petit_truc(df2[family])\n",
    "    # Tester la stationnarité de la série originale \n",
    "    if p_val < 0.05:\n",
    "        ordreP = 0\n",
    "        stat_data[family] = series\n",
    "     \n",
    "    if p_val > 0.05:\n",
    "        # Appliquer des différentiations successives\n",
    "        for p in range(1, 6):\n",
    "            diff_series = series.diff(periods=p).dropna()\n",
    "            p_val1 = test_stationarity(diff_series)\n",
    "            if p_val1 <= 0.05:\n",
    "                ordreP = p\n",
    "                stat_data[family] = diff_series\n",
    "                break  \n",
    "            else:\n",
    "                continue\n",
    "        # Si toujours non stationnaire après différentiation\n",
    "        if p_val1 > 0.05:\n",
    "            # Appliquer une transformation logarithmique\n",
    "            log_series = apply_log(series, p=petit_truc)\n",
    "            loga = 1       \n",
    "             \n",
    "            # Tester la stationnarité de la série log-transformée\n",
    "            p_val2 = test_stationarity(log_series)\n",
    "            if p_val2 < 0.05:\n",
    "                print(\"mauvaise fam\")\n",
    "                #ordreP = 0\n",
    "            if p_val2 > 0.05:\n",
    "                # Appliquer des différentiations successives sur la série log-transformée\n",
    "                for j in range(1, 6):\n",
    "                    diff_log_series = log_series.diff(periods=j).dropna()\n",
    "                    p_val3 = test_stationarity(diff_log_series)\n",
    "                    if p_val3 <= 0.05:\n",
    "                        ordreP = j\n",
    "                        stat_data[family] = diff_log_series\n",
    "                        break\n",
    "    results_list.append({\"family\": family, \"ordreP\": ordreP, \"loga\": loga})\n",
    "\n",
    "stat_data = pd.DataFrame(stat_data)\n",
    "results_df = pd.DataFrame(results_list)\n",
    "df_diff = stat_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Division en jeu de données d'entrainement et de test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 50\n",
      "Test set: 3\n"
     ]
    }
   ],
   "source": [
    "#le point de coupure \n",
    "n = 3\n",
    "# Diviser les données\n",
    "df_train = df_diff.iloc[:-3]\n",
    "df_test = df_diff.iloc[-3:]\n",
    "\n",
    "# Vérifier les tailles des ensembles d'entraînement et de test\n",
    "print('Training set:', len(df_train))\n",
    "print('Test set:', len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiation du modèle, fit sur les données, calcul des prédictions des différences et calcul des vraies valeurs prédites "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordervarclust = { 2: 2,  3: 1, 1:1 }\n",
    "decalages = dict()\n",
    "train_size = len(df_train)\n",
    "test_pred_df2 = pd.DataFrame()\n",
    "reelPred = pd.DataFrame()\n",
    "\n",
    "for cluster in df_clust['clusters'].unique():\n",
    "\n",
    "    families_in_cluster = df_clust[df_clust['clusters'] == cluster]['productfamilies']\n",
    "    \n",
    "    # Sélectionner les colonnes correspondantes dans le DataFrame des séries différentiées\n",
    "    \n",
    "    cluster_data_train = df_train[families_in_cluster].dropna()  \n",
    "    cluster_data_test  = df_test[families_in_cluster]\n",
    "\n",
    "    model = VAR(cluster_data_train)\n",
    "    order = ordervarclust[cluster]\n",
    "    results = model.fit(order)\n",
    "    lag_order = results.k_ar\n",
    "\n",
    "    train_pred = results.fittedvalues\n",
    "    test_pred = results.forecast(cluster_data_train.values[-lag_order:], steps=len(cluster_data_test))\n",
    "\n",
    "    test_pred_df = pd.DataFrame(test_pred, index=cluster_data_test.index, columns=cluster_data_test.columns)\n",
    "    max_diff_order = 0\n",
    "\n",
    "    for family in families_in_cluster:\n",
    "        transfo_family = dictTransformations.loc[family]\n",
    "        diff_order = transfo_family['ordreP']  \n",
    "        max_diff_order = max(max_diff_order, diff_order)   \n",
    "\n",
    "    for family in families_in_cluster:\n",
    " \n",
    "        transfo_family = dictTransformations.loc[family]\n",
    "        diff_order = transfo_family['ordreP']  \n",
    "        log_order =  transfo_family['loga'] \n",
    "        if diff_order > 0:\n",
    "\n",
    "            # Reconstruction de la partie train\n",
    "\n",
    "            decalage = max_diff_order - diff_order\n",
    "            reconsTrain = deDiffFamily(orig = dfOrig[family].iloc[(lag_order+decalage):train_size], diff = train_pred[family], order = diff_order,log_order = log_order )\n",
    "            decalages[family] = (lag_order+decalage)\n",
    "\n",
    "            # Reconstruction de la partie test\n",
    "\n",
    "            last_values = dfOrig[family][train_size:train_size + diff_order]\n",
    "            reconstructed_forecast = list()\n",
    "            current_values = list(last_values)\n",
    "    \n",
    "            for diff in test_pred_df[family].values.flatten():\n",
    "                next_value = current_values[-1] + diff\n",
    "                reconstructed_forecast.append(next_value)\n",
    "                current_values.append(next_value)\n",
    "\n",
    "            reconsout = pd.Series(reconstructed_forecast,index=test_pred_df[family].index, dtype=test_pred_df[family].dtype)\n",
    "\n",
    "            # Si il y a eu un log pour rendre la série stationnaire on le retire en passant un exponentiel\n",
    "\n",
    "            if log_order == 1:\n",
    "                reconstructed_forecast = np.exp(reconstructed_forecast)\n",
    "\n",
    "        elif diff_order == 0 :\n",
    "\n",
    "            decalages[family] = 0\n",
    "            reconsTrain = train_pred[family]\n",
    "            reconsout = pd.DataFrame(test_pred_df[family])\n",
    "\n",
    "        # on remets tout dans deux dataframes\n",
    "        reelPred[family] = reconsTrain\n",
    "        test_pred_df2[family] = reconsout\n",
    "reelPred = reelPred.dropna()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul des métriques d'évaluation du modèle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list_train = list()\n",
    "metrics_list_test = list()\n",
    "for cluster in df_clust['clusters'].unique():\n",
    "    families_in_cluster = df_clust[df_clust['clusters'] == cluster]['productfamilies']\n",
    "    metrics_df_train = pd.DataFrame(index=dfOrig[families_in_cluster].columns, columns=['MAPE_train' ,'SMAPE_train', 'SMAPE_ADJ_train', 'R2_train', 'R2_ajuste_train'])\n",
    "    metrics_df_test  = pd.DataFrame(index=dfOrig[families_in_cluster].columns, columns=['MAPE_test', 'SMAPE_test', 'SMAPE_ADJ_test','R2_test', 'R2_ajuste_test'])\n",
    "    for family in families_in_cluster:   \n",
    "        x = decalages[family]\n",
    "        y_train_true = dfOrig[x:train_size][family]\n",
    "        y_train_pred = reelPred[family]\n",
    "        y_train_true = y_train_true[(-y_train_pred.shape[0]):] # on mets le vecteur de valeurs vraies à la même taille que celui des prédictions\n",
    "        y_test_true = dfOrig[train_size:][family]\n",
    "        y_test_pred = test_pred_df2[family]\n",
    "\n",
    "        n_train = len(y_train_true)\n",
    "        n_test = len(y_test_true)\n",
    "        p = dfOrig.shape[1]\n",
    "\n",
    "        mape_train = np.mean(np.abs(y_train_pred - y_train_true)/np.abs(y_train_true))  \n",
    "        mape_test = np.mean(np.abs(y_test_pred - y_test_true)/np.abs(y_test_true))  \n",
    "        \n",
    "        smape_train = 1/len(y_train_true) * (np.sum(2 * np.abs(y_train_pred-y_train_true) / (np.abs(y_train_true) + np.abs(y_train_pred))*100))\n",
    "        smape_test  = 1/len(y_test_true) * (np.sum(2 * np.abs(y_test_pred-y_test_true) / (np.abs(y_test_true) + np.abs(y_test_pred))*100))\n",
    "        \n",
    "        smape_adj_train = 1/(y_train_true.size) * (np.sum( np.abs(y_train_pred-y_train_true) / (np.abs(y_train_true) + np.abs(y_train_pred))*100))\n",
    "        smape_adj_test  = 1/(y_test_true.size) * (np.sum( np.abs(y_test_pred-y_test_true) / (np.abs(y_test_true) + np.abs(y_test_pred))*100))\n",
    "        \n",
    "        r2_train = r2_score(y_train_true, y_train_pred)\n",
    "        r2_test = r2_score(y_test_true, y_test_pred)\n",
    "        r2_ajuste_train =  r2_ajuste(r2_train,n_train,p)\n",
    "        r2_ajuste_test = r2_ajuste(r2_test,n_test,p)\n",
    "        \n",
    "        metrics_df_train.loc[family] = [mape_train, smape_train,smape_adj_train,  r2_train,  r2_ajuste_train]\n",
    "        metrics_df_test.loc[family] = [ mape_test,  smape_test, smape_adj_test,  r2_test, r2_ajuste_test]\n",
    "\n",
    "    metrics_df_train['Cluster'] = cluster\n",
    "    metrics_df_test['Cluster'] = cluster\n",
    "\n",
    "    metrics_list_train.append(metrics_df_train) \n",
    "    metrics_list_test.append(metrics_df_test)\n",
    "\n",
    "final_metrics_train = pd.concat(metrics_list_train)\n",
    "final_metrics_test = pd.concat(metrics_list_test)\n",
    "\n",
    "final_metrics_train.to_csv(\"metrics_train.csv\")\n",
    "final_metrics_test.to_csv(\"metric_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracé des courbes des valeurs vraies et des prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordervarclust = { 2: 2,  3: 1, 1:1 }\n",
    "for cluster in df_clust['clusters'].unique():\n",
    "\n",
    "    families_in_cluster = df_clust[df_clust['clusters'] == cluster]['productfamilies']\n",
    "    cluster_data_train = df_train[families_in_cluster] \n",
    "\n",
    "    y_train_true = dfOrig[x:train_size][families_in_cluster]\n",
    "    y_train_pred = reelPred[families_in_cluster]\n",
    "    y_train_true = y_train_true[(-y_train_pred.shape[0]):]\n",
    "    y_test_true = dfOrig[train_size:][families_in_cluster]\n",
    "    y_test_pred = test_pred_df2[families_in_cluster]\n",
    "    \n",
    "    for column in families_in_cluster:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(y_train_true.index, y_train_true[column], label='Train Actual')\n",
    "       \n",
    "        plt.plot(y_train_pred.index, y_train_pred[column], label='Train Predicted', linestyle='--')\n",
    "        plt.plot(y_test_true.index, y_test_true[column], label='Test Actual')\n",
    "        plt.plot(y_test_pred.index, y_test_pred[column], label='Test Predicted', linestyle='--')\n",
    "      \n",
    "        plt.title(f'Cluster {cluster} - {column}')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Values')\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devdaveyBickford",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
