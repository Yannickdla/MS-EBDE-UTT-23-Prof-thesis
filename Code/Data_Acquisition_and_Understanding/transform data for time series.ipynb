{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv, to_datetime, pivot_table\n",
    "import string "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture du fichier combiné de données de vente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## penser à modifier le dossier d'accès au fichier\n",
    "dfTot = read_csv(\"data Combined Buffer\\\\combined_sales_2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On va rajouter une fonction qui va anonymiser les données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_letter(index):\n",
    "    \"\"\"Convertit un index en lettre, gestion des cas où l'index est supérieur à 25 (a à z)\"\"\"\n",
    "    letters = string.ascii_uppercase\n",
    "    result = []\n",
    "    while index >= 0:\n",
    "        result.append(letters[index % 26])\n",
    "        index = index // 26 - 1\n",
    "    return ''.join(reversed(result))\n",
    "\n",
    "def anon_df(df,cols):\n",
    "    \"\"\"\n",
    "    Retourne un dataframe avec un ensemble de colonnes anonymisées \n",
    "    Input: \n",
    "    df : le dataframe en entrée\n",
    "    cols : la liste de colonne qu'on souhaite rendre anonyme \n",
    "    \n",
    "    \"\"\"\n",
    "    # On va parcourir les colonnes de la liste de colonne cols voulue \n",
    "    # On lui affecte ensuite un numéro \n",
    "    \n",
    "    for col_name in cols:\n",
    "        keys = {cats: index_to_letter(index = i) for i, cats in enumerate(df[col_name].unique()) }\n",
    "        df[col_name] = df[col_name].apply(lambda x:keys[x])\n",
    "    print(keys)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On retire les éléments après conseil par l'expert \n",
    "\n",
    "## On ne prend que la F08 car on ne regarde que des objets qui sont comparables \n",
    "## Les entités F01 -> F07 ne sont pas prises car elles ne sont plus d'actualité dans les filiales de DB\n",
    "\n",
    "## On prend le H4_GP03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfTot = dfTot[dfTot[\"Product Family\"] != \"#AmbiguousMemberID - 900008\"]\n",
    "dfTot = dfTot[dfTot[\"Product Family\"] != \"#AmbiguousMemberID - 900009\"]\n",
    "\n",
    "dfTot = dfTot[dfTot[\"ENTITY\"] == \"F08\"]\n",
    "\n",
    "dfTot['Product Family'] = dfTot['Product Family'].replace({\n",
    "    'F_DEL_MINE': 'F_DEL',\n",
    "    'F_DEL_SEISM': 'F_DEL'\n",
    "})\n",
    "\n",
    "dfTot.loc[:,'UniqueID'] = dfTot['CUSTOMER GROUP ID'].astype(str) + '|' + dfTot['PRODUCT'].astype(str) +'|'+dfTot['date_dt'].astype(str)\n",
    "\n",
    "## Conversion de Australia \n",
    "\n",
    "dfTot[\"CONTINENT\"] = dfTot[\"CONTINENT\"].str.replace(\"AUSTRALIA/OCEANIA\",\"AUSTRALIA_OCEANIA\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On va rendre anonyme le jeu de données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"Product Family\"]\n",
    "dfTot = anon_df(df = dfTot,cols = cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On crée le fichier pour l'analyse exploratoire "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfextrait = dfTot[['date_dt', 'INDICATORS', 'SIGNEDDATA', 'PRODUCT','CUSTOMER GROUP ID','UniqueID',\"Product Family\"]]\n",
    "dfextraitqte = dfextrait[dfextrait[\"INDICATORS\"] == \"QTE\"]\n",
    "df_pivotqte =  dfextraitqte.pivot_table(index='Product Family', columns=['date_dt'], values='SIGNEDDATA', aggfunc='sum')\n",
    "\n",
    "df_pivotqte.fillna(0, inplace=True)\n",
    "\n",
    "df_pivotqte.to_csv(\"Product families over time.csv\",index=\"True\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On crée les extractions de fichiers pour le pivot table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfextrait = dfTot[['date_dt', 'INDICATORS', 'SIGNEDDATA', 'PRODUCT','CUSTOMER GROUP ID','UniqueID',\"Product Family\"]]\n",
    "dfextrait2 = dfextrait[dfextrait[\"Product Family\"].isin(['F_DTC', 'F_DT5', 'F_DTC_BTY', 'F_DNE', 'F_DEL'])]\n",
    "dfextrait3 = dfTot[['date_dt', 'INDICATORS', 'SIGNEDDATA', 'PRODUCT','CUSTOMER GROUP ID','UniqueID',\"CONTINENT\"]] \n",
    "dfextrait4 = dfTot[['date_dt', 'INDICATORS', 'SIGNEDDATA', 'PRODUCT','CUSTOMER GROUP ID','UniqueID',\"SECTEUR\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction qui permet de découper les données de ventes en plusieurs fichiers csv par catégorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scinde_DF(input_df, wanted_col, index_column, columns, values_column, output_dir,aggfunc='sum'):\n",
    "\n",
    "    dfinput = input_df\n",
    "    for el in dfinput[wanted_col].unique():\n",
    "        df_filtered = dfinput[dfinput[wanted_col] == el]\n",
    "        \n",
    "        # Créer le pivot table\n",
    "        df_trait = pivot_table(df_filtered, index=index_column, columns=columns ,values=values_column, aggfunc=aggfunc)\n",
    "        df_trait.reset_index(inplace=True)\n",
    "\n",
    "        df_trait['date'] = df_trait[index_column].str.split(\"|\").str[-1]\n",
    "        df_trait['date'] = to_datetime(df_trait['date'], format='%Y-%m-%d', exact=True)\n",
    "\n",
    "        df_trait = df_trait.drop(columns=index_column)\n",
    "        df_trait = df_trait.fillna(value=0)\n",
    "\n",
    "        # Enregistrer le pivot table au format CSV\n",
    "        output_file = f\"{output_dir}{el}.csv\"\n",
    "        df_trait.to_csv(output_file)\n",
    "        print(f\"Pivot table for '{el}' saved to '{output_file}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On génère les fichiers pour chaque catégorie "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scinde_DF(input_df = dfextrait2, wanted_col = \"Product Family\", index_column = \"UniqueID\", columns = \"INDICATORS\", values_column = \"SIGNEDDATA\", output_dir='data Famille Spec\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scinde_DF(input_df = dfextrait, wanted_col = \"Product Family\", index_column = \"UniqueID\", columns = \"INDICATORS\", values_column = \"SIGNEDDATA\", output_dir='data Prod fam tot\\\\')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devdaveyBickford",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
