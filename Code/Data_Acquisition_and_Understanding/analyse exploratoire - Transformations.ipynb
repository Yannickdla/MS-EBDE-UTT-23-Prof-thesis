{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv, to_datetime, DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import boxcox\n",
    "import plotly.express as px \n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller, kpss#,acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from numpy import  random, log,arange, log2, log10\n",
    "import numpy as np\n",
    "#from math import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation des Données :\n",
    "\n",
    "Graphique des séries temporelles : Visualisez la série pour identifier les tendances, les saisonnalités, et les anomalies.\n",
    "Graphique des composantes de la décomposition : Utilisez la décomposition de la série temporelle pour extraire les composantes de tendance, de saisonnalité, et résiduelle.\n",
    "Statistiques Descriptives :\n",
    "\n",
    "Résumé statistique : Calculez les statistiques descriptives telles que la moyenne, la médiane, l'écart-type, etc.\n",
    "Histogramme : Visualisez la distribution des valeurs de la série temporelle.\n",
    "Test de Stationnarité :\n",
    "\n",
    "Test de Dickey-Fuller augmenté (ADF) : Vérifiez si la série est stationnaire ou non.\n",
    "Test de Kwiatkowski-Phillips-Schmidt-Shin (KPSS) : Un autre test pour vérifier la stationnarité.\n",
    "Analyse de l'Autocorrélation :\n",
    "\n",
    "Fonction d'Autocorrélation (ACF) : Visualisez les corrélations entre les valeurs de la série à différents décalages.\n",
    "Fonction d'Autocorrélation partielle (PACF) : Visualisez les corrélations partielles pour mieux comprendre les relations entre les décalages.\n",
    "Détection et Gestion des Saisonnalités et Tendances :\n",
    "\n",
    "Décomposition STL : Utilisez la décomposition STL (Seasonal and Trend decomposition using Loess) pour analyser les composantes de la série.\n",
    "Transformation logarithmique ou différence : Appliquez des transformations pour stabiliser la variance ou rendre la série stationnaire.\n",
    "Détection des Anomalies et des Points de Rupture :\n",
    "\n",
    "Détection des valeurs aberrantes : Identifiez les valeurs anormalement élevées ou basses.\n",
    "Détection des points de rupture : Identifiez les points où la série change de comportement.\n",
    "Analyse Fréquentielle :\n",
    "\n",
    "Analyse de Fourier : Identifiez les fréquences dominantes dans la série pour comprendre la saisonnalité.\n",
    "Cross-Correlation Analysis :\n",
    "\n",
    "Analyse des corrélations croisées : Si vous avez plusieurs séries temporelles, analysez les relations entre elles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import du jeu de données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\A'\n",
      "D:\\WK\\ydongue\\AppData\\Local\\Temp\\ipykernel_6016\\4091362910.py:3: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  dfTime = read_csv(\"D:\\Alternance_2023_UTT\\MS EBDE UTT 23 Prof thesis\\Sample_Data\\Processed\\Product families over time.csv\")\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "dfTime = read_csv(\"D:\\Alternance_2023_UTT\\MS EBDE UTT 23 Prof thesis\\Sample_Data\\Processed\\Product families over time.csv\")\n",
    "\n",
    "df2 = dfTime.set_index('Product Family').T\n",
    "df2.index = to_datetime(df2.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations qu'on va appliquer aux séries pour les rendre stationnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******\n",
      "A\n",
      "*******\n",
      "*******\n",
      "B\n",
      "The series is already stationary.\n",
      "*******\n",
      "*******\n",
      "C\n",
      "The series is already stationary.\n",
      "*******\n",
      "*******\n",
      "D\n",
      "The series is already stationary.\n",
      "*******\n",
      "*******\n",
      "E\n",
      "The series is already stationary.\n",
      "*******\n",
      "*******\n",
      "F\n",
      "*******\n",
      "*******\n",
      "G\n",
      "The series is already stationary.\n",
      "*******\n",
      "*******\n",
      "H\n",
      "*******\n",
      "*******\n",
      "I\n",
      "The series is already stationary.\n",
      "*******\n",
      "*******\n",
      "J\n",
      "The series is already stationary.\n",
      "*******\n",
      "*******\n",
      "K\n",
      "*******\n",
      "*******\n",
      "L\n",
      "The series is already stationary.\n",
      "*******\n",
      "*******\n",
      "M\n",
      "*******\n",
      "*******\n",
      "N\n",
      "*******\n",
      "*******\n",
      "O\n",
      "*******\n",
      "*******\n",
      "P\n",
      "*******\n",
      "*******\n",
      "Q\n",
      "The series is already stationary.\n",
      "*******\n",
      "                    A         B         C         D          E          F  \\\n",
      "2020-03-01  -145778.0  119501.0  161600.0  199000.0   536000.0  1173970.0   \n",
      "2020-04-01    33548.0  113901.0   83800.0  236775.0        0.0 -1278343.0   \n",
      "2020-05-01   -68616.0   75220.0  143400.0   51750.0  1469000.0  2467319.0   \n",
      "2020-06-01    47216.0  166397.0  189600.0  188000.0        0.0 -1854166.0   \n",
      "2020-07-01   171812.0  269196.0  162200.0  382750.0        0.0  -542519.0   \n",
      "2020-08-01  -328488.0   17438.0   10800.0   26000.0        0.0   -72843.0   \n",
      "2020-09-01   252420.0  266455.0  200800.0  472600.0  1012000.0  1745182.0   \n",
      "2020-10-01    54368.0  285428.0  171400.0  286300.0   749000.0  -206070.0   \n",
      "2020-11-01  -236656.0  149307.0   81600.0  307200.0        0.0 -1511954.0   \n",
      "2020-12-01    79096.0   39635.0   32400.0  329200.0  1307000.0  3967849.0   \n",
      "2021-01-01   168428.0   34983.0   50400.0   59000.0    10000.0 -3998906.0   \n",
      "2021-02-01   148004.0  164014.0  387600.0  138200.0        0.0    24869.0   \n",
      "2021-03-01  -613305.0  262669.0  257200.0  452950.0   654000.0  2139094.0   \n",
      "2021-04-01   350678.0  318792.0  193200.0  204075.0        0.0 -2147807.0   \n",
      "2021-05-01   152602.0  169475.0  131400.0  236200.0   291000.0  1028460.0   \n",
      "2021-06-01  -347378.0  235727.0  228800.0  132000.0   706000.0  -576073.0   \n",
      "2021-07-01   375836.0  341679.0  135200.0  584000.0        0.0  -404506.0   \n",
      "2021-08-01  -721610.0    5222.0   10000.0    2000.0        0.0   -76626.0   \n",
      "2021-09-01  1015477.0  188743.0  278200.0  372300.0   779000.0  1470613.0   \n",
      "2021-10-01  -565312.0  142613.0   56000.0   70900.0   683000.0  -365214.0   \n",
      "2021-11-01   -84154.0  236906.0  156000.0  227900.0        0.0 -1039754.0   \n",
      "2021-12-01   292353.0  258946.0  200000.0   72700.0   216000.0   433893.0   \n",
      "2022-01-01  -468952.0  122584.0  192200.0  240000.0   762000.0   941310.0   \n",
      "2022-02-01   538197.0  101123.0   98400.0   98800.0    15000.0 -1436952.0   \n",
      "2022-03-01  -343688.0  400340.0  288000.0  705000.0        0.0    46333.0   \n",
      "2022-04-01   140560.0  146092.0   40800.0   88400.0        0.0   -16663.0   \n",
      "2022-05-01   -85123.0  123207.0  274000.0  153000.0        0.0   -35608.0   \n",
      "2022-06-01    29220.0  239450.0  130000.0  393300.0   827000.0    81685.0   \n",
      "2022-07-01   218789.0  203104.0  337200.0  164000.0    50000.0   -82431.0   \n",
      "2022-08-01  -449871.0  114641.0   10800.0  300800.0        0.0  1227790.0   \n",
      "2022-09-01   478935.0  186194.0  267400.0  229400.0   200000.0 -1205968.0   \n",
      "2022-10-01  -217453.0  257832.0  128000.0   70250.0   626000.0   903968.0   \n",
      "2022-11-01   -26869.0  200230.0  188000.0  442900.0        0.0  -876011.0   \n",
      "2022-12-01   150212.0  365199.0  256200.0  695500.0  1094000.0   865647.0   \n",
      "2023-01-01  -176662.0  193882.0  115800.0  328000.0    15000.0  -855989.0   \n",
      "2023-02-01   342764.0  414507.0  134800.0  267900.0   659000.0   715374.0   \n",
      "2023-03-01  -429732.0  294261.0  161000.0  238500.0   781000.0    99045.0   \n",
      "2023-04-01   338168.0  175609.0  192200.0   93850.0        0.0  -764611.0   \n",
      "2023-05-01  -403966.0  333654.0  102600.0  201675.0    60000.0   -89464.0   \n",
      "2023-06-01   186060.0  280265.0   80400.0  446325.0   860000.0  2206025.0   \n",
      "2023-07-01   293198.0  577910.0  201600.0  309650.0   843000.0  -614471.0   \n",
      "2023-08-01  -503640.0   28765.0   92000.0  208000.0        0.0 -1512552.0   \n",
      "2023-09-01   422508.0  343272.0  106000.0   97650.0    80000.0   691110.0   \n",
      "2023-10-01  -409184.0  347239.0  124000.0  153800.0   754000.0  2127186.0   \n",
      "2023-11-01   480682.0  407821.0   42400.0  406350.0   962000.0 -1949916.0   \n",
      "2023-12-01  -413176.0  174893.0  121600.0  198800.0     5000.0  -933018.0   \n",
      "2024-01-01   242428.0  416912.0   64400.0  186625.0   115000.0   178684.0   \n",
      "2024-02-01   -56726.0  274550.0  210800.0  276700.0   881000.0  1473212.0   \n",
      "2024-03-01   -84242.0  274805.0   84300.0   13000.0   287000.0   282393.0   \n",
      "2024-04-01   113156.0  137369.0  282800.0  140550.0        0.0 -1899229.0   \n",
      "2024-05-01  -195362.0  483521.0   98600.0   10200.0  1047000.0  1461150.0   \n",
      "\n",
      "                   G         H        I          J        K       L         M  \\\n",
      "2020-03-01  207862.0   11750.0      0.0   117352.0      0.0     0.0       0.0   \n",
      "2020-04-01   90724.0  -46875.0      0.0   217802.0      0.0     0.0       0.0   \n",
      "2020-05-01   35636.0   -2322.0   6000.0    20001.0      0.0     0.0       0.0   \n",
      "2020-06-01   68560.0   43442.0    130.0   241779.0      0.0     0.0       0.0   \n",
      "2020-07-01  143071.0  -45243.0   5000.0    12028.0      0.0     0.0       0.0   \n",
      "2020-08-01    5000.0   -3726.0      0.0        0.0      0.0     0.0       0.0   \n",
      "2020-09-01  120583.0   44582.0    205.0   125001.0      0.0     0.0       0.0   \n",
      "2020-10-01   75854.0   25956.6    495.0        0.0      0.0     0.0       0.0   \n",
      "2020-11-01  155676.0  -77713.6   2300.0    51902.0      0.0     0.0       0.0   \n",
      "2020-12-01   25551.0   21661.0  17000.0        0.0      0.0     0.0       0.0   \n",
      "2021-01-01   85050.0   13930.0  10000.0        0.0      0.0     0.0       0.0   \n",
      "2021-02-01   77172.0  -15215.0   5000.0    33001.0  14479.0     0.0       0.0   \n",
      "2021-03-01  175222.0  -11684.0    500.0   142803.0 -14479.0     0.0       0.0   \n",
      "2021-04-01  101601.0   35937.0    200.0     6152.0      0.0     0.0       0.0   \n",
      "2021-05-01   44188.0  -18004.0     95.0    17703.0      0.0     0.0       0.0   \n",
      "2021-06-01   91913.0   -7508.0  12550.0    62480.0   5600.0     0.0       0.0   \n",
      "2021-07-01  101680.0   32129.0   6958.0     4113.0     80.0     0.0       0.0   \n",
      "2021-08-01   43918.0   -2310.0   2700.0        0.0  -5680.0     0.0       0.0   \n",
      "2021-09-01   40757.0  -41192.0    543.0    51003.0      0.0     0.0       0.0   \n",
      "2021-10-01   75599.0   54726.0   1050.0   231506.0   2000.0  2000.0       0.0   \n",
      "2021-11-01   86651.0  -34750.6      0.0   161004.0  -2000.0     0.0       0.0   \n",
      "2021-12-01   59719.0    7800.6      0.0    15377.0      0.0     0.0  115274.0   \n",
      "2022-01-01  101516.0  -29584.0    300.0   218403.0      0.0     0.0 -115274.0   \n",
      "2022-02-01   57331.0   60255.0  10000.0   275855.0  34720.0     0.0       0.0   \n",
      "2022-03-01   70569.0  -27501.8    102.8   317281.0 -34720.0     0.0       0.0   \n",
      "2022-04-01  167182.0   36826.8    480.0   323404.0   4712.0     0.0       0.0   \n",
      "2022-05-01   59800.0  -46158.0      2.0   182608.0   4944.0     0.0       0.0   \n",
      "2022-06-01   51136.0   65754.5   2700.0   154107.0  17821.0  1000.0       0.0   \n",
      "2022-07-01   78208.0  -99569.5   4583.0   314254.0 -12258.0  2976.0   94581.2   \n",
      "2022-08-01  111912.0     521.0   2000.0   145951.0 -15219.0     0.0  -94581.2   \n",
      "2022-09-01  105515.0   49187.0      0.0   582532.0  26400.0  2800.0   11760.0   \n",
      "2022-10-01   86624.0  -30354.2     82.0   161202.0   6720.0   112.0  -11760.0   \n",
      "2022-11-01  161905.0   33762.2   1547.0   411479.0  28480.0     0.0    1000.0   \n",
      "2022-12-01  108026.0  -34838.0   1000.0   265602.0 -30400.0     0.0     600.0   \n",
      "2023-01-01   45048.0   69083.0   1091.0   511053.0  28800.0     0.0    1800.0   \n",
      "2023-02-01  118887.0  -28621.0   2500.0   478803.0  -4560.0     0.0  224560.0   \n",
      "2023-03-01  113300.0   44978.9    300.0   210654.0  -2400.0     0.0 -163360.0   \n",
      "2023-04-01   70855.0  -35123.9   2840.0   519404.0 -53040.0     0.0  -53710.0   \n",
      "2023-05-01  113017.0   72394.0    300.0   165681.0  49840.0     0.0    1510.0   \n",
      "2023-06-01   38377.0 -107190.8  10680.0   676782.0 -49840.0     0.0    2600.0   \n",
      "2023-07-01   81552.0  -23231.2      0.0  1022982.0  36000.0     0.0  264599.2   \n",
      "2023-08-01   13120.0  -11879.0    300.0   135602.0 -13760.0     0.0 -278399.2   \n",
      "2023-09-01   33201.0   40826.0    799.0   127353.0  -3360.0     0.0   89376.0   \n",
      "2023-10-01  116031.0    9616.0   1240.0   136202.0  17840.0     0.0  215891.0   \n",
      "2023-11-01   90017.0   29085.0   8015.0   163903.0   -720.0     0.0  -41333.0   \n",
      "2023-12-01   35019.0   17414.0   3951.0    51001.0  31840.0  1008.0  168481.0   \n",
      "2024-01-01   40605.0  -11519.0   1950.0   295355.0 -18480.0     0.0 -379448.0   \n",
      "2024-02-01   43028.0   -9163.5     40.0   584152.0 -49360.0     0.0  304399.0   \n",
      "2024-03-01   58681.0   -5950.5   2500.0    36275.0  79280.0     0.0  -54704.0   \n",
      "2024-04-01  104436.0    1140.0    436.0   365856.0  -4640.0   504.0 -104352.0   \n",
      "2024-05-01   44979.0   69628.0  53041.0   193004.0   7360.0  4106.0  118850.0   \n",
      "\n",
      "                    N         O          P      Q  \n",
      "2020-03-01   0.000000       0.0   0.000000    0.0  \n",
      "2020-04-01   0.000000       0.0   0.000000    0.0  \n",
      "2020-05-01   0.000000       0.0   0.000000    0.0  \n",
      "2020-06-01   0.000000       0.0   0.000000    0.0  \n",
      "2020-07-01   0.000000       0.0   0.000000    0.0  \n",
      "2020-08-01   0.000000       0.0   0.000000    0.0  \n",
      "2020-09-01   0.000000       0.0   0.000000    0.0  \n",
      "2020-10-01   0.000000       0.0   0.000000    0.0  \n",
      "2020-11-01   0.000000       0.0   0.000000    0.0  \n",
      "2020-12-01   0.000000       0.0   0.000000    0.0  \n",
      "2021-01-01   0.000000       0.0   0.000000    0.0  \n",
      "2021-02-01   0.000000       0.0   0.000000    0.0  \n",
      "2021-03-01   0.000000       0.0   0.000000    0.0  \n",
      "2021-04-01   0.000000       0.0   0.000000    0.0  \n",
      "2021-05-01   0.000000       0.0   0.000000    0.0  \n",
      "2021-06-01   0.000000       0.0   0.000000    0.0  \n",
      "2021-07-01   0.000000       0.0   0.000000    0.0  \n",
      "2021-08-01   0.000000       0.0   0.000000    0.0  \n",
      "2021-09-01   0.000000       0.0   0.000000    0.0  \n",
      "2021-10-01   0.000000       0.0   0.000000    0.0  \n",
      "2021-11-01   0.000000       0.0   0.000000    0.0  \n",
      "2021-12-01   0.000000       0.0   0.000000    0.0  \n",
      "2022-01-01   0.000000       0.0   0.000000    0.0  \n",
      "2022-02-01   0.000000       0.0   0.000000    0.0  \n",
      "2022-03-01   0.000000       0.0   0.000000    0.0  \n",
      "2022-04-01   0.000000       0.0   0.000000    0.0  \n",
      "2022-05-01   0.000000       0.0   0.000000    0.0  \n",
      "2022-06-01   0.000000       0.0   0.000000    0.0  \n",
      "2022-07-01   0.000000   50400.0   0.000000    0.0  \n",
      "2022-08-01   0.000000 -100800.0   0.000000    0.0  \n",
      "2022-09-01   0.000000   50400.0   0.000000    0.0  \n",
      "2022-10-01   0.000000       0.0   0.000000    0.0  \n",
      "2022-11-01   0.000000       0.0   0.000000    0.0  \n",
      "2022-12-01   0.000000       0.0   0.000000    0.0  \n",
      "2023-01-01  13.652993       0.0   0.000000    0.0  \n",
      "2023-02-01 -27.305986       0.0   0.000000    0.0  \n",
      "2023-03-01  13.652993   46800.0   0.000000    0.0  \n",
      "2023-04-01   0.000000  -93600.0   0.000000    0.0  \n",
      "2023-05-01  13.955273   46800.0   0.000000    0.0  \n",
      "2023-06-01 -27.910547       0.0   0.000000    0.0  \n",
      "2023-07-01  28.835495  100750.0   0.000000    0.0  \n",
      "2023-08-01 -29.760443 -201500.0   0.000000    0.0  \n",
      "2023-09-01  14.880222  100750.0   0.000000    0.0  \n",
      "2023-10-01   0.000000   32400.0  11.512935    0.0  \n",
      "2023-11-01   0.000000  -64800.0   3.401188    0.0  \n",
      "2023-12-01  15.984564  198000.0   0.889262    0.0  \n",
      "2024-01-01 -31.969129 -331200.0   1.613539    0.0  \n",
      "2024-02-01  15.984564  241200.0  -1.662672    0.0  \n",
      "2024-03-01   0.000000  -93600.0  -3.799488    0.0  \n",
      "2024-04-01   0.000000   61200.0   3.236569  960.0  \n",
      "2024-05-01  11.512935  -43200.0   1.782949    0.0  \n",
      "   family loga  Petit_truc ordreP\n",
      "0       A    0         NaN      2\n",
      "1       B    0         NaN      0\n",
      "2       C    0         NaN      0\n",
      "3       D    0         NaN      0\n",
      "4       E    0         NaN      0\n",
      "5       F    0         NaN      1\n",
      "6       G    0         NaN      0\n",
      "7       H    0         NaN      1\n",
      "8       I    0         NaN      0\n",
      "9       J    0         NaN      0\n",
      "10      K    0         NaN      1\n",
      "11      L    0         NaN      0\n",
      "12      M    0         NaN      1\n",
      "13      N    1     0.00002      2\n",
      "14      O    0         NaN      2\n",
      "15      P    1     0.00288      1\n",
      "16      Q    0         NaN      0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\WK\\ydongue\\AppData\\Local\\Temp\\ipykernel_6016\\2787426611.py:85: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_transformations = pd.concat([df_transformations, transformations_df], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import boxcox\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def test_stationarity_adf(series):\n",
    "    # Test ADF\n",
    "    result = adfuller(series, autolag='AIC')\n",
    "    p_value = result[1]\n",
    "    return p_value < 0.05  # Return True if the series is stationary\n",
    "\n",
    "def determine_petit_truc(series):\n",
    "    min_positive_value = series[series > 0].min()\n",
    "    val = 0.00001\n",
    "    return min_positive_value * val\n",
    "\n",
    "def differentiate_until_stationary(series, max_diff=3):\n",
    "    diff_count = 0\n",
    "    while diff_count < max_diff:\n",
    "        if test_stationarity_adf(series):\n",
    "            return series, diff_count\n",
    "        series = series.diff().dropna()  # Differentiate the series\n",
    "        diff_count += 1\n",
    "    return series, diff_count\n",
    "\n",
    "def process_time_series(series):\n",
    "    transformations = {\n",
    "        \"loga\": 0,\n",
    "        \"Petit_truc\": np.nan,\n",
    "        \"ordreP\": 0\n",
    "    }\n",
    "\n",
    "    original_index = series.index  # Save the original index\n",
    "\n",
    "    if test_stationarity_adf(series):\n",
    "        print(\"The series is already stationary.\")\n",
    "        return series, transformations\n",
    "    \n",
    "    # Differentiate the series up to 3 times (initial count not recorded in \"Différenciations\")\n",
    "    differentiated_series, initial_diff_count = differentiate_until_stationary(series)\n",
    "\n",
    "    if test_stationarity_adf(differentiated_series):\n",
    "        transformations[\"ordreP\"] = initial_diff_count  # Record the initial differentiations\n",
    "        # Adjust index to match the length of the differentiated series\n",
    "        differentiated_series.index = original_index[-len(differentiated_series):]\n",
    "        return differentiated_series, transformations\n",
    "    \n",
    "    # Apply the logarithmic transformation\n",
    "    petit_truc = determine_petit_truc(series)\n",
    "    transformed_series = np.log(series + petit_truc)\n",
    "    transformations[\"loga\"] = 1\n",
    "    transformations[\"Petit_truc\"] = petit_truc\n",
    "    \n",
    "    # After the logarithmic transformation, differentiate the series\n",
    "    differentiated_series, post_log_diff_count = differentiate_until_stationary(transformed_series)\n",
    "    transformations[\"ordreP\"] = post_log_diff_count  # Record only the differentiations after transformation\n",
    "\n",
    "    if test_stationarity_adf(differentiated_series):\n",
    "        # Adjust index to match the length of the differentiated series\n",
    "        differentiated_series.index = original_index[-len(differentiated_series):]\n",
    "        return differentiated_series, transformations\n",
    "    \n",
    "    # Adjust index to match the length of the differentiated series\n",
    "    differentiated_series.index = original_index[-len(differentiated_series):]\n",
    "    return differentiated_series, transformations\n",
    "\n",
    "# Example usage with fictitious data\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialization of DataFrames to store the results\n",
    "    df_differentiated = pd.DataFrame()  # For differentiated series\n",
    "    df_transformations = pd.DataFrame(columns=[\"family\", \"loga\", \"Petit_truc\", \"ordreP\"])  # For applied transformations\n",
    "\n",
    "    for fam in df2.columns: \n",
    "        print(\"*******\")\n",
    "        print(fam)\n",
    "        processed_family, transformations = process_time_series(df2[fam])\n",
    "        df_differentiated[fam] = processed_family  # Save the differentiated series\n",
    "        transformations[\"family\"] = fam\n",
    "\n",
    "        # Create a DataFrame from the transformations and remove columns containing only NaNs\n",
    "        transformations_df = pd.DataFrame([transformations]).dropna(axis=1, how='all')\n",
    "\n",
    "        # Use pd.concat instead of append\n",
    "        df_transformations = pd.concat([df_transformations, transformations_df], ignore_index=True)\n",
    "        print(\"*******\")\n",
    "\n",
    "    # Display the resulting DataFrames\n",
    "    print(df_differentiated)\n",
    "    print(df_transformations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations pour revenir sur la série originale \n",
    "## Ceci pourrait vous être utile si vous voulez vérifier vos transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def invert_transformations(df_differentiated, df_transformations, df_original):\n",
    "    df_reverted = pd.DataFrame(index=df_original.index)\n",
    "\n",
    "    for index, row in df_transformations.iterrows():\n",
    "        family = row['family']\n",
    "        orderP = int(row['ordreP'])\n",
    "        loga = int(row['loga'])\n",
    "        petit_truc = row.get('Petit_truc', 0)\n",
    "\n",
    "        inverted_series = df_differentiated[family].copy()\n",
    "        revertSerie = pd.Series(index = df_original.index)\n",
    "        revertSerie.update(df_differentiated[family].copy())\n",
    "      \n",
    "        if orderP == 2:\n",
    "            \n",
    "            print(family, orderP)\n",
    "            \n",
    "            # Retour à l'ordre 1 \n",
    "            diff_ordre_1 = df_original[family].diff().dropna()\n",
    "            first_value_ordre_1 = diff_ordre_1.iloc[0]\n",
    "            vectBuff2 = (first_value_ordre_1 + np.cumsum(inverted_series))\n",
    "            inverted_series_ordre_1 = np.concatenate(([first_value_ordre_1], vectBuff2))\n",
    "            \n",
    "            # Puis retour à l'ordre 0\n",
    "            \n",
    "            first_value_orig = df_original[family].iloc[0]\n",
    "            if loga == 0:\n",
    "                inverted_series = np.concatenate(([first_value_orig], (first_value_orig + np.cumsum(inverted_series_ordre_1))))\n",
    "            if loga == 1:\n",
    "                invbuff = np.concatenate(([first_value_orig], (first_value_orig + np.cumsum(inverted_series_ordre_1))))\n",
    "                inverted_series = np.exp(invbuff) - petit_truc\n",
    "            #inverted_series = inverted_series[:len(df_original[family])]\n",
    "\n",
    "        elif orderP == 1:\n",
    "            print(family, orderP)\n",
    "            revertSerie.iloc[1] = df_original[family].iloc[1] - df_original[family].iloc[0]\n",
    "            \n",
    "            vectBuff = ( np.cumsum(revertSerie.dropna()) + df_original[family].iloc[0] )\n",
    "            \n",
    "            #inverted_series = np.concatenate( ( [df_original[family].iloc[0]] , vectBuff  ) )\n",
    "            if loga == 0:\n",
    "                inverted_series = np.concatenate( ( [df_original[family].iloc[0]] , vectBuff  ) )\n",
    "            if loga == 1:\n",
    "                invbuff = np.concatenate( ( [df_original[family].iloc[0]] , vectBuff  ) )\n",
    "                inverted_series = np.exp(invbuff) - petit_truc\n",
    "            \n",
    "        elif orderP == 0:    \n",
    "            inverted_series = df_original[family]\n",
    "\n",
    "        df_reverted[family] = inverted_series\n",
    "\n",
    "    return df_reverted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\A'\n",
      "D:\\WK\\ydongue\\AppData\\Local\\Temp\\ipykernel_6016\\1442876378.py:2: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  df_differentiated.to_csv('D:\\Alternance_2023_UTT\\MS EBDE UTT 23 Prof thesis\\Sample_Data\\For_Modeling\\\\series_differenciees.csv')  # Enregistre les séries différenciées\n",
      "D:\\WK\\ydongue\\AppData\\Local\\Temp\\ipykernel_6016\\1442876378.py:3: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  df_transformations.to_csv('D:\\Alternance_2023_UTT\\MS EBDE UTT 23 Prof thesis\\Sample_Data\\For_Modeling\\\\transformations_appliquees.csv', index=False)  # Enregistre les transformations appliquées\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarder les DataFrames dans des fichiers CSV\n",
    "df_differentiated.to_csv('D:\\Alternance_2023_UTT\\MS EBDE UTT 23 Prof thesis\\Sample_Data\\For_Modeling\\\\series_differenciees.csv')  # Enregistre les séries différenciées\n",
    "df_transformations.to_csv('D:\\Alternance_2023_UTT\\MS EBDE UTT 23 Prof thesis\\Sample_Data\\For_Modeling\\\\transformations_appliquees.csv', index=False)  # Enregistre les transformations appliquées\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devdaveyBickford",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
